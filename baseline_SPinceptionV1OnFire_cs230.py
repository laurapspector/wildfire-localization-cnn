'''
May 2019
This script generates baseline metrics for the wildfire localization project. It takes as input
a directory of isolated superpixels and .npy files listing the filenames and ground truth labels,
generated by the script isolate_superpixels.py. It classifies each superpixel using the pre-trained
SP-InceptionV1-OnFire model, computes the F1 score for prediction, then merges positively
predicted superpixels to compute the IoU compared to the ground truth.

The InceptionV1-OnFire model and the pre-trained weights for SP-InceptionV1-OnFire 
can be acquired by cloning this repo: https://github.com/tobybreckon/fire-detection-cnn.git

The script is intended to be called from within the fire-detection-cnn directory, which is also
where the data directory should be stored.
'''
################################################################################

import cv2
import os
import sys
import math
import numpy as np
import argparse
from tqdm import tqdm

################################################################################

import tflearn
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_2d, max_pool_2d, avg_pool_2d
from tflearn.layers.normalization import local_response_normalization
from tflearn.layers.merge_ops import merge
from tflearn.layers.estimator import regression

################################################################################

from inceptionV1OnFire import construct_inceptionv1onfire

###################### USEFUL FUNCTIONS ###########################################

def merge_and_iou(y, y_hat, filenames):
    '''
    Script to compute F1 score and IoU

    Inputs:
        y = numpy array, ground truth labels (0 or 1)
        y_hat = numpy array, predicted labels (0 or 1)
        filenames = numpy array, filenames input to classifier

    Returns:
        F1_score = float, F1 score
        similarity = float, average IoU score
    '''

    # Retain only positive (ground truth or predicted) superpixels
    gt_sp = filenames[np.nonzero(y)]
    pred_sp = filenames[np.nonzero(y_hat)]

    # Create directory to store merged positive superpixels for manual examination
    meta_img = os.path.join(args.data_dir, 'IoU_images')
    os.mkdir(meta_img)

    # Initialize list to store IoU scores for each image
    similarity = []

    # Remove suffix from filenames in order to reduce to whole image numbers
    # By ignoring superpixel index
    filenames_split = [i.split('_rgb')[0] for i in filenames]

    # Loop through filenames by whole image
    for img_num in tqdm(set(filenames_split)):

        # Merge all positive superpixels for that image
        gt_merged = merge_superpixels(gt_sp, meta_img)
        pred_merged = merge_superpixels(pred_sp, meta_img)
        
        # Compute IoU
        intersection = cv2.bitwise_and(gt_merged, pred_merged)
        union = cv2.bitwise_or(gt_merged, pred_merged)
        total_intersection = np.sum(np.sum((intersection > 0)))
        total_union = np.sum(np.sum((union > 0)))
        similarity.append(total_intersection / total_union)

    # Save IoU for each image in a numpy array
    np.save(os.path.join(meta_img, 'IoU'), np.asarray(similarity))
    
    # Compute F1 score
    tp = len(np.where(y * y_hat == 1)[0])
    fp = len(np.where((1-y) * y_hat == 1)[0])
    fn = len(np.where(y - y * y_hat == 1)[0])
    precision = tp / (tp + fp)
    recall = tp / (tp + fn)
    F1_score = 2 * (precision * recall)/(precision + recall)

    return round(F1_score, 3), round(np.mean(np.asarray(similarity)), 3)

def merge_superpixels(pixel_set, store_dir):
    '''
    Function to merge positive superpixels (predicted or ground truth)
    for a given image

    Inputs:
        pixel_set = numpy array, filenames corresponding to positive superpixels

    Returns:
        merged = numpy array, the 1 layer image of merged positive superpixels
    '''
    # Generate 'empty' image
    merged = np.zeros(shape=(224, 224, 3), dtype = "uint8")
    merged = gt_merged[:,:,0]

    # Pare down superpixel list to contain only positive superpixels (ground truth or predicted)
    fire_superpixels = [gt_pixel.split('_rgb')[0] + '_gt' + gt_pixel.split('_rgb')[1] for gt_pixel in pixel_set if gt_pixel.split('_rgb')[0].startswith(img_num)]

    # Merge positive superpixels with empty image iteratively
    for superpixel in fire_superpixels:
        superpixel = cv2.imread(superpixel)[:,:,0]
        merged = cv2.bitwise_or(merged, superpixel)

    # Save merged image
    save_path = os.path.join(store_dir, img_num.split('/')[-1] + '_' + pixel_set.split('sp')[0] + 'merged.png')
    cv2.imwrite(save_path, merged)

    return merged

################################################################################

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', default='all_db_fire', help="Location of whole images")
    parser.add_argument('--output_dir', default='all_db_fire/isolated_superpixels', help="Location of X and Y arrays and isolated superpixels")

    args = parser.parse_args()

    assert os.path.isdir(args.output_dir), "Couldn't find the directory {}".format(args.output_dir)

    # Load file list
    filenames = np.load(os.path.join(args.output_dir, 'x_test.npy'))

    # construct and display model OUT
    model = construct_inceptionv1onfire (224, 224, training=False)
    print("Constructed SP-InceptionV1-OnFire ...")

    model.load(os.path.join("models/SP-InceptionV1-OnFire", "sp-inceptiononv1onfire"),weights_only=True)
    print("Loaded CNN network weights ...")

    # Load ground truth labels
    Y_labels = np.load(os.path.join(args.output_dir, 'y_test.npy'))

    # OUT

    # Initialize list to store y_hat labels
    predictions = []

    # Loop through files and classify using loaded model
    for (file, ground_truth) in tqdm(zip(filenames, Y_labels)):
    	img = cv2.imread(file)
    	print('Running prediction...')
    	output = model.predict([img])
    	output = int(round(output[0][0]))
    	predictions.append(output)
    	#print(file, ground_truth, output)

    # OUT

    # Save y_hat for re-loading later if desired
    np.save(os.path.join(args.output_dir, 'y_pred'), np.asarray(predictions))
    #predictions = np.load(os.path.join(args.output_dir, 'y_pred.npy'))

    # Compute IoU and F1 score
    (F1_score, similarity) = merge_and_iou(Y_labels, np.asarray(predictions), filenames)

    print('proportion fire superpixels in y', len(Y_labels[np.nonzero(Y_labels)]) / len(Y_labels))
    print('F1_score', F1_score)
    print('IoU', similarity)
